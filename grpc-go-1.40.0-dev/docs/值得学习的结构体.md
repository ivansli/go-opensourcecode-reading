
# gRpc 中几个重要的结构


## 通过 chan 实现类似 MQ 的数据缓存队列

> 代码位置：
> 1. internal/buffer/unbounded.go
> 2. internal/transport/transport.go

```go
// internal/buffer/unbounded.go
type Unbounded struct {
	c       chan interface{}
	mu      sync.Mutex

	// 把信息作为日志记录在 backlog 中
	backlog []interface{}
}

// NewUnbounded returns a new instance of Unbounded.
// 创建一个 新的 Unbounded 实例
func NewUnbounded() *Unbounded {
    return &Unbounded{c: make(chan interface{}, 1)}
}

// Put adds t to the unbounded buffer.
// put 添加 数据 t 到 unbounded 缓冲中
func (b *Unbounded) Put(t interface{}) {
    b.mu.Lock()
    if len(b.backlog) == 0 {
        select {
        case b.c <- t: // chan 有容量可以存储
            b.mu.Unlock()
            return // 发送到 chan 成功之后就退出
        default: // chan 已满，则走这里，通过下面逻辑存储到 backlog
        }
    }
    
    // t 添加到日志队列中
    b.backlog = append(b.backlog, t)
    b.mu.Unlock()
}

// Load将最早的缓冲数据(如果有的话)发送到Get()返回的读通道
// 用户每次从读取通道读取值时都要调用这个函数
//
// 值得注意的时，每当消费掉 chan 中的一个数据时，就需要调用该方法一次，必须要调用！！！
func (b *Unbounded) Load() {
    b.mu.Lock()
    
    // backlog 有没有消费的数据，则取出来再次发送到 chan
    if len(b.backlog) > 0 {
        select {
        case b.c <- b.backlog[0]: // 取出来第一个，尝试发送到 chan
            b.backlog[0] = nil // backlog 第一个设置为 nil，有利于 垃圾回收
            b.backlog = b.backlog[1:] // 移除 第一个位置
        default: // 发送失败，走这里
        }
    }
    
    b.mu.Unlock()
}


// 获取通道 chan
func (b *Unbounded) Get() <-chan interface{} {
    return b.c
}


// internal/transport/transport.go
type recvBuffer struct {
    c       chan recvMsg
    mu      sync.Mutex
    backlog []recvMsg
    err     error
}

func newRecvBuffer() *recvBuffer {
    b := &recvBuffer{
        c: make(chan recvMsg, 1),
    }
    return b
}
```
值得注意的是：
1. 这些结构体中的 chan 在创建时容量都是1
2. 带有 backlog 切片，用在 chan 无容量时暂存储发送过来的数据，不然会造成阻塞或者数据丢失
3. 带有 sync.Mutex 锁，防止在并发操作时造成数据竞争

总的来说，作用就是：通过带有 backlog 的通道暂存发送过来的数据，然后再被其他地方消费
> 类似 GPM模型中 P 的 runnext 与 runq，当有新的goroutine出现时，先存放在容量为1的 runnext <br/>
> 如果 优先队列 runnext 不为空，则存放在 容量为 256 的本地队列 runq 中 <br/>
> 等待 M的进一步消费，如果 runnext 为空，则会去 runq 中拿取 goroutine 来消费 <br/>
> <br/>
> 有一点需要注意的是：<br/>
> GPM 中 关于 P 中的 goroutine 不需要加锁 <br/>
> 上面的两个结构体则需要加锁，加锁就会导致性能会稍微下降。但是却能实现一个 类似 MQ 的队列


## 通过 chan 封装一个 Event 对象

代码位置：
> internal/grpcsync/event.go

```go
type Event struct {
	fired int32
	c     chan struct{}
	o     sync.Once // 保证 fire、c只被执行一次操作
}

// 用来关闭通道
func (e *Event) Fire() bool {
    // ret 表示当前是否是真正执行了 Do() 方法
    // 只有第一个执行的协程才会返回true， 其他都是false
    ret := false
    
    // 保证 chan 只被真正关闭一次，即使 多次调用 Fire()
    // 否则 多次 close chan 会导致 panic
    e.o.Do(func() {
        atomic.StoreInt32(&e.fired, 1)
        
        close(e.c)
        ret = true
    })
    
    return ret
}

// Done returns a channel that will be closed when Fire is called.
//
// 返回一个当 Fire 被调用时会关闭的通道
func (e *Event) Done() <-chan struct{} {
    return e.c
}

// HasFired returns true if Fire has been called.
// 判断是否执行了 Fire，即通道是否官博
func (e *Event) HasFired() bool {
    return atomic.LoadInt32(&e.fired) == 1
}

// NewEvent returns a new, ready-to-use Event.
// 返回一个新的 Event
func NewEvent() *Event {
    return &Event{c: make(chan struct{})}
}
```

通过对 chan 的封装，实现了一个可以多次关闭 chan 并不会导致 panic 的功能 <br/>
同时，还可以检测通道是否已经关闭，非常适合用于通过 chan 达到事件通知的地方



